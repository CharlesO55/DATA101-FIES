{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "835c5e8e-65b7-4780-be8f-d4463fe3d3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import geopandas as gpd\n",
    "from plotly.colors import qualitative as pColors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5a9769-e83d-4da5-995f-4c5bafa6d6e6",
   "metadata": {},
   "source": [
    "## Pandas and GeoJson Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4be3a8c-b2a4-45b9-8285-dac547f1ef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDataframe():\n",
    "    df_Raw = pd.read_csv('../Datasets/Family Income and Expenditure.csv')\n",
    "\n",
    "    #Remove whitespaces like in ' ARMM'\n",
    "    df_Raw['Region'] = df_Raw['Region'].apply(lambda x: x.strip())\n",
    "\n",
    "    #Change the food column name\n",
    "    df_Raw.rename(columns={\n",
    "                    'Bread and Cereals Expenditure':'Bread and Cereals',\n",
    "                    'Meat Expenditure':'Meat',\n",
    "                    'Total Rice Expenditure':'Rice', \n",
    "                    'Total Fish and  marine products Expenditure':'Seafood', \n",
    "                    'Fruit Expenditure':'Fruits', \n",
    "                    'Vegetables Expenditure':'Vegetables'\n",
    "                  },\n",
    "                  inplace=True\n",
    "                 )\n",
    "\n",
    "    df_Raw['Household Head Education Level'] = \"None\"\n",
    "    def SetEduLevel(ref_Dataframe, str_ScanFor, str_Replace):\n",
    "        for currStr in str_ScanFor:\n",
    "            ref_Dataframe.loc[ref_Dataframe['Household Head Highest Grade Completed'].str.contains(currStr), 'Household Head Education Level'] = str_Replace\n",
    "\n",
    "\n",
    "    SetEduLevel(df_Raw, ['No Grade Completed'], 'None')\n",
    "    SetEduLevel(df_Raw, ['Preschool'], 'Preschool')\n",
    "    SetEduLevel(df_Raw, ['Grade 1', 'Grade 2','Grade 3','Grade 4','Grade 5','Grade 6','Elementary Graduate'], 'Primary')\n",
    "    SetEduLevel(df_Raw, ['High School'], 'Secondary')\n",
    "    SetEduLevel(df_Raw, ['Program'], 'TESDA')\n",
    "    SetEduLevel(df_Raw, ['College', 'Post Secondary', 'Baccalaureate', 'Business and Administration Programs', 'Humanities Programs', 'Engineering and Engineering Trades Programs','Social and Behavioral Science Programs','Health Programs','Engineering and Engineering trades Programs','Computing/Information Technology Programs','Mathematics and Statistics Programs','Law Programs','Journalism and Information Programs','Architecture and Building Programs','Manufacturing and Processing Programs', 'Life Sciences Programs','Physical Sciences Programs', 'Arts Programs','Veterinary Programs'], \n",
    "                'Tertiary')\n",
    "\n",
    "\n",
    "    def SetRegionID(ref_Dataframe):\n",
    "        RegionID = GetRegionIDs()\n",
    "        for x in RegionID.keys():\n",
    "            ref_Dataframe.loc[ref_Dataframe['Region'] == x, 'RegionID'] = RegionID[x]\n",
    "\n",
    "    SetRegionID(df_Raw)\n",
    "    \n",
    "    return df_Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82731b39-0111-42c4-8daf-cdb74be3369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetColumnNames_ForFood():\n",
    "    return ['Bread and Cereals','Meat', 'Rice', 'Seafood', 'Fruits', 'Vegetables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7cb0bd5-6895-441a-9023-b6922259ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetGeoJson():\n",
    "    gj_PhMap = gpd.read_file('../Datasets/country.0.001.json')\n",
    "\n",
    "    # MATCH REGION NAME TO OUR CSV \n",
    "    gj_PhMap['adm1_en'] = gj_PhMap['adm1_en'].replace(\n",
    "        ['Region I (Ilocos Region)', 'Region II (Cagayan Valley)',\n",
    "           'Region III (Central Luzon)', 'Region IV-A (CALABARZON)',\n",
    "           'Region V (Bicol Region)', 'Region VI (Western Visayas)',\n",
    "           'Region VII (Central Visayas)', 'Region VIII (Eastern Visayas)',\n",
    "           'Region IX (Zamboanga Peninsula)', 'Region X (Northern Mindanao)',\n",
    "           'Region XI (Davao Region)', 'Region XII (SOCCSKSARGEN)',\n",
    "           'National Capital Region (NCR)',\n",
    "           'Cordillera Administrative Region (CAR)', 'Region XIII (Caraga)',\n",
    "           'MIMAROPA Region',\n",
    "           'Bangsamoro Autonomous Region In Muslim Mindanao (BARMM)']\n",
    "        ,\n",
    "    \n",
    "        ['I - Ilocos Region', 'II - Cagayan Valley',\n",
    "         'III - Central Luzon', 'IVA - CALABARZON',\n",
    "         'V - Bicol Region', 'VI - Western Visayas', \n",
    "         'VII - Central Visayas', 'VIII - Eastern Visayas',\n",
    "         'IX - Zasmboanga Peninsula', 'X - Northern Mindanao',\n",
    "         'XI - Davao Region', 'XII - SOCCSKSARGEN',\n",
    "         'NCR',\n",
    "         'CAR', 'Caraga',\n",
    "         'IVB - MIMAROPA', \n",
    "         'ARMM'])\n",
    "    return gj_PhMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568472f2-ee4c-43b4-a6c3-c5bf758dc60f",
   "metadata": {},
   "source": [
    "# All Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ab0858-9d9d-4fe4-9b1e-f34dcc1f70d3",
   "metadata": {},
   "source": [
    "## Choropleth of Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ad0daa-ebe8-4ca2-8f17-1fd96dc8c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetFig_Choropleth(ref_Dataframe, ref_GeoJson, agg_Mode):\n",
    "    match agg_Mode:\n",
    "        case 'Max':\n",
    "           agg_Income = ref_Dataframe.groupby('Region')['Total Household Income'].max()\n",
    "        case 'Min':\n",
    "           agg_Income = ref_Dataframe.groupby('Region')['Total Household Income'].min()\n",
    "        case 'Median':\n",
    "           agg_Income = ref_Dataframe.groupby('Region')['Total Household Income'].median()\n",
    "        case default:\n",
    "           agg_Income = ref_Dataframe.groupby('Region')['Total Household Income'].mean()\n",
    "    \n",
    "    \n",
    "    fig = px.choropleth_mapbox(\n",
    "        data_frame = agg_Income,\n",
    "        geojson = ref_GeoJson,\n",
    "        locations = agg_Income.index, #'Region',\n",
    "        featureidkey = 'properties.adm1_en',\n",
    "        color = agg_Income.values, #'Total Household Income',\n",
    "        center = {'lat': 12.738500, 'lon': 121.766632},\n",
    "        mapbox_style= 'carto-positron',\n",
    "        zoom = 4,\n",
    "        opacity = 0.3,\n",
    "        height=600,\n",
    "        labels={'color':'Php'},\n",
    "        title='Income per Region',\n",
    "        color_continuous_scale=px.colors.sequential.thermal\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c5300e-b34e-4a37-a154-471fea097a67",
   "metadata": {},
   "source": [
    "## Pie Chart of Top 10 Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4133de46-6a55-4feb-9650-fda1dc3ebe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filter_TopJobs(ref_Dataframe, region_Name, min_Row, max_Row):\n",
    "    df_AllJobs = ref_Dataframe[ref_Dataframe['Region'] == region_Name]['Household Head Occupation'].value_counts()\n",
    "    return df_AllJobs[min_Row:max_Row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "107a44d7-70ee-434a-8821-237164ee22b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetFig_MostEmployedJobs(ref_Dataframe, region_Name, min_Row, max_Row):\n",
    "    df_Top10Jobs = Filter_TopJobs(ref_Dataframe, region_Name, 0, 10)\n",
    "    fig = px.pie(df_Top10Jobs, values = df_Top10Jobs.values, names = df_Top10Jobs.index, title='Top 10 Most Employed Jobs in ' + region_Name, hover_name=df_Top10Jobs.index,\n",
    "                color_discrete_map=pColors.Light24)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee404295-baf9-401d-b646-4a9466c82126",
   "metadata": {},
   "source": [
    "## Stacked Barchart of Food Breakdown per Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb643f1c-1bc1-4226-9861-d08d4326563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetFig_FoodBreakdown(ref_Dataframe, selected_Foods, grouping_By):\n",
    "    avg_FoodExpenses = ref_Dataframe.groupby(grouping_By)[selected_Foods].mean()\n",
    "    \n",
    "    fig = px.bar(data_frame = avg_FoodExpenses, x=avg_FoodExpenses.index, y=selected_Foods, \n",
    "                 title='Average Food Expenses' , \n",
    "                 labels={'value':'Php', 'variable':'Food Expenses'},\n",
    "                 color_discrete_map = \n",
    "                     {'Meat': pColors.Light24[0], \n",
    "                      'Seafood': pColors.D3[0], \n",
    "                      'Fruits': pColors.Plotly[5],             \n",
    "                      'Vegetables': pColors.D3[2], \n",
    "                      'Rice': pColors.Alphabet[-2], \n",
    "                      'Bread and Cereals':pColors.Plotly[4]},\n",
    "                 text_auto=\".3s\") \n",
    "    \n",
    "    fig.update_traces(textposition='inside')\n",
    "    fig.update_layout(barmode='stack', uniformtext_minsize=8, uniformtext_mode='hide')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047d2c52-4653-4d23-ac1f-5bad8ee4a60e",
   "metadata": {},
   "source": [
    "## Stacked Barchart of Income vs Expenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f41faa-1bb6-42b9-a088-f957e5d265f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetFig_IncomeVsExpenses(ref_Dataframe, selected_Regions, selected_Category, is_Collapse):\n",
    "    #ref_Dataframe = GetDataframe() \n",
    "    #selected_Regions = ['NCR', 'CAR']\n",
    "    #selected_Category = ['Income', 'Utilities']\n",
    "    #is_Collapse = False\n",
    "    \n",
    "    queryCols =['Region']\n",
    "    for i in selected_Category:\n",
    "        for j in GetExpenseTypes()[i]:\n",
    "            queryCols.append(j)\n",
    "    \n",
    "    df_IncomeAndExpenses = ref_Dataframe[queryCols].copy()\n",
    "    df_IncomeAndExpenses.set_index('Region', inplace=True)\n",
    "    \n",
    "    if (is_Collapse):\n",
    "        for i in selected_Category:\n",
    "            df_IncomeAndExpenses[i] = df_IncomeAndExpenses[GetExpenseTypes()[i]].sum(axis=1)\n",
    "            df_IncomeAndExpenses.drop(columns=GetExpenseTypes()[i], inplace=True)\n",
    "    \n",
    "    aggByRegion = df_IncomeAndExpenses.groupby('Region')[df_IncomeAndExpenses.columns].mean()\n",
    "    \n",
    "    # FILTER TO ONLY OUR SELECTED REGIONS\n",
    "    aggByRegion = aggByRegion.loc[selected_Regions]\n",
    "    \n",
    "    # MAKE EXPENSES NEGATIVE\n",
    "    aggByRegion.loc[:, ~aggByRegion.columns.isin(['Income', 'Total Household Income'])] *= -1\n",
    "    \n",
    "    # PLOT THE GRAPH\n",
    "    fig = px.bar(data_frame = aggByRegion, x=aggByRegion.index, y=aggByRegion.columns, barmode='relative',\n",
    "                 title = 'Average Income and Expenses per Region',\n",
    "                 height = 600,\n",
    "                 labels={\n",
    "                    'value' : 'Php',\n",
    "                    'variable' : 'Income and Expenses'\n",
    "                },\n",
    "                 color_discrete_map = \n",
    "                     {\n",
    "                         'Total Household Income': pColors.Plotly[0], \n",
    "                         'Income': pColors.Plotly[0], \n",
    "                         'Food': pColors.D3[2], \n",
    "                         'Total Food Expenditure': pColors.D3[2], \n",
    "                         'Vices': pColors.Light24[0], \n",
    "                         'Tobacco Expenditure': pColors.Light24[0], \n",
    "                         'Alcoholic Beverages Expenditure': pColors.G10[1], \n",
    "                         'Clothing' : pColors.Plotly[-2],\n",
    "                         'Clothing, Footwear and Other Wear Expenditure' : pColors.Plotly[-2],\n",
    "                         'Utilities':pColors.Dark2[1],\n",
    "                         'Housing and water Expenditure':pColors.Pastel1[0],\n",
    "                         'Imputed House Rental Value': pColors.Plotly[-1],\n",
    "                         'Communication Expenditure':pColors.T10[2],\n",
    "                         'Miscellaneous Goods and Services Expenditure':pColors.D3[-2],\n",
    "                         'Transportation Expenditure': pColors.T10[-2],\n",
    "                         'Crop Farming and Gardening expenses': pColors.D3[-5],\n",
    "                         'Social' : pColors.Plotly[3],\n",
    "                         'Special Occasions Expenditure' : pColors.Plotly[3],\n",
    "                         'Restaurant and hotels Expenditure' : pColors.G10[4],\n",
    "                         'Education': pColors.Plotly[5],\n",
    "                         'Education Expenditure':pColors.Plotly[5],\n",
    "                         'Healthcare': pColors.Dark2[-1], \n",
    "                         'Medical Care Expenditure': pColors.Dark2[-1]\n",
    "                     },\n",
    "                text_auto=\".3s\"\n",
    "                )\n",
    "    \n",
    "    fig.update_traces(textfont_size=14,  textposition='inside')\n",
    "    fig.update_layout(uniformtext_minsize=10, uniformtext_mode='hide')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bbb565-149a-4f79-aa18-3746d4bcda27",
   "metadata": {},
   "source": [
    "# Helper Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ff64913-bde7-4984-9b7e-9680ea5a8e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetGroupings_ForFoodBreakdown():\n",
    "    return [ 'Household Head Sex',\n",
    "       'Household Head Age', 'Household Head Marital Status',\n",
    "       'Household Head Education Level',\n",
    "       'Household Head Job or Business Indicator', \n",
    "       'Household Head Class of Worker', 'Type of Household',\n",
    "       'Total Number of Family members',\n",
    "       'Members with age less than 5 year old',\n",
    "       'Members with age 5 - 17 years old',\n",
    "       'Total number of family members employed', 'Type of Building/House',\n",
    "       'Type of Roof', 'Type of Walls', 'House Floor Area', 'House Age',\n",
    "       'Number of bedrooms', 'Tenure Status', 'Toilet Facilities',\n",
    "       'Electricity', 'Main Source of Water Supply', 'Number of Television',\n",
    "       'Number of CD/VCD/DVD', 'Number of Component/Stereo set',\n",
    "       'Number of Refrigerator/Freezer', 'Number of Washing Machine',\n",
    "       'Number of Airconditioner', 'Number of Car, Jeep, Van',\n",
    "       'Number of Landline/wireless telephones', 'Number of Cellular phone',\n",
    "       'Number of Personal Computer', 'Number of Stove with Oven/Gas Range',\n",
    "       'Number of Motorized Banca', 'Number of Motorcycle/Tricycle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b9d1da2-798b-4d02-ba3b-3e8fcc3b3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetExpenseTypes(): \n",
    "    return {\n",
    "            \"Income\": ['Total Household Income'],\n",
    "            \"Food\": ['Total Food Expenditure'],\n",
    "            \"Education\": ['Education Expenditure'],\n",
    "            \"Healthcare\": ['Medical Care Expenditure'],\n",
    "            \"Clothing\": ['Clothing, Footwear and Other Wear Expenditure'],\n",
    "            \"Utilities\":['Housing and water Expenditure', 'Imputed House Rental Value', 'Communication Expenditure','Miscellaneous Goods and Services Expenditure','Transportation Expenditure','Crop Farming and Gardening expenses'],\n",
    "            \"Social\" : ['Special Occasions Expenditure', 'Restaurant and hotels Expenditure'],\n",
    "            \"Vices\": ['Tobacco Expenditure', 'Alcoholic Beverages Expenditure']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65390360-0d3d-42a1-85e4-9b4cdf20cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetRegionIDs():\n",
    "    return {\n",
    "            'I - Ilocos Region' : 1, \n",
    "            'CAR' : 1.5,\n",
    "            'II - Cagayan Valley' : 2,\n",
    "            'III - Central Luzon' : 3,\n",
    "            'NCR': 3.5,\n",
    "            'IVA - CALABARZON' : 4,\n",
    "            'IVB - MIMAROPA' : 4.5, \n",
    "            'V - Bicol Region' : 5,\n",
    "            'VI - Western Visayas' : 6,\n",
    "            'VII - Central Visayas' : 7,\n",
    "            'VIII - Eastern Visayas' : 8, \n",
    "            'IX - Zasmboanga Peninsula' : 9,\n",
    "            'X - Northern Mindanao' : 10, \n",
    "            'XI - Davao Region' : 11,\n",
    "            'XII - SOCCSKSARGEN' : 12,\n",
    "            'Caraga' : 13,  \n",
    "            'ARMM' : 14\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec019a51-90bc-4c0c-aeae-eab7365cdb80",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 27\u001b[0m\n\u001b[0;32m     22\u001b[0m aggByRegion \u001b[38;5;241m=\u001b[39m aggByRegion\u001b[38;5;241m.\u001b[39mloc[selected_Regions]\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#aggByRegion['Total Expenses']= aggByRegion.sum(axis=1)\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[43maggByRegion\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal Expenses\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m df_IncomeAndExpenses\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     28\u001b[0m px\u001b[38;5;241m.\u001b[39mscatter(y\u001b[38;5;241m=\u001b[39maggByRegion[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Household Income\u001b[39m\u001b[38;5;124m'\u001b[39m] , x\u001b[38;5;241m=\u001b[39maggByRegion[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Expenses\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4094\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4091\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4092\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4093\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4094\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4303\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4294\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4295\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4296\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4301\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4302\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4303\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4306\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4307\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4308\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4309\u001b[0m     ):\n\u001b[0;32m   4310\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4311\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:5039\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5037\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Series):\n\u001b[0;32m   5038\u001b[0m         value \u001b[38;5;241m=\u001b[39m Series(value)\n\u001b[1;32m-> 5039\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_reindex_for_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m   5042\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:12312\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[1;34m(value, index)\u001b[0m\n\u001b[0;32m  12308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m  12309\u001b[0m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[0;32m  12310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m  12311\u001b[0m         \u001b[38;5;66;03m# duplicate axis\u001b[39;00m\n\u001b[1;32m> 12312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m  12314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m  12315\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible index of inserted column with frame index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m  12316\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m  12317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reindexed_value, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:12307\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[1;34m(value, index)\u001b[0m\n\u001b[0;32m  12305\u001b[0m \u001b[38;5;66;03m# GH#4107\u001b[39;00m\n\u001b[0;32m  12306\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m> 12307\u001b[0m     reindexed_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m  12308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m  12309\u001b[0m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[0;32m  12310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m  12311\u001b[0m         \u001b[38;5;66;03m# duplicate axis\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4977\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[1;34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   4960\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   4961\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m   4962\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4975\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4976\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m-> 4977\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:5521\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[0;32m   5520\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5522\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m   5523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:5544\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5541\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   5543\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[1;32m-> 5544\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\n\u001b[0;32m   5546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5548\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[0;32m   5549\u001b[0m obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   5550\u001b[0m     {axis: [new_index, indexer]},\n\u001b[0;32m   5551\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5552\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5553\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   5554\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:4433\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   4430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot handle a non-unique multi-index!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m   4432\u001b[0m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4434\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4435\u001b[0m     indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "ref_Dataframe = GetDataframe() \n",
    "selected_Regions = ['NCR', 'CAR']\n",
    "selected_Category = ['Income', 'Utilities']\n",
    "is_Collapse = False\n",
    "\n",
    "queryCols =['Region']\n",
    "for i in selected_Category:\n",
    "    for j in GetExpenseTypes()[i]:\n",
    "        queryCols.append(j)\n",
    "\n",
    "df_IncomeAndExpenses = ref_Dataframe[queryCols].copy()\n",
    "df_IncomeAndExpenses.set_index('Region', inplace=True)\n",
    "\n",
    "# if (is_Collapse):\n",
    "#     for i in selected_Category:\n",
    "#         df_IncomeAndExpenses[i] = df_IncomeAndExpenses[GetExpenseTypes()[i]].sum(axis=1)\n",
    "#         df_IncomeAndExpenses.drop(columns=GetExpenseTypes()[i], inplace=True)\n",
    "\n",
    "aggByRegion = df_IncomeAndExpenses.groupby('Region')[df_IncomeAndExpenses.columns].median()\n",
    "\n",
    "# FILTER TO ONLY OUR SELECTED REGIONS\n",
    "aggByRegion = aggByRegion.loc[selected_Regions]\n",
    "\n",
    "#aggByRegion['Total Expenses']= aggByRegion.sum(axis=1)\n",
    "\n",
    "\n",
    "px.scatter(y=aggByRegion['Total Household Income'] , x=aggByRegion['Total Expenses'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
